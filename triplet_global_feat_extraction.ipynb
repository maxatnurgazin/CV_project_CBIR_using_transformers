{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import transforms, models, datasets\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import faiss\n",
    "from map import evaluate\n",
    "import pickle\n",
    "from revisited_dataset import RevisitedDataset\n",
    "from triplet_dataset import TripletData, TripletLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'rparis6k'\n",
    "\n",
    "path = 'E:/Datasets/paris/'\n",
    "root = f'E:/Datasets/paris/{dataset_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_names =  ['vit_small_patch16_224',\n",
    "                     'deit3_small_patch16_224',\n",
    "                     'swinv2_cr_small_224',\n",
    "                     'resnet50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T13:09:53.050630Z",
     "iopub.status.busy": "2022-12-02T13:09:53.050377Z",
     "iopub.status.idle": "2022-12-02T13:09:53.067923Z",
     "shell.execute_reply": "2022-12-02T13:09:53.067175Z",
     "shell.execute_reply.started": "2022-12-02T13:09:53.050596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "\n",
    "# Datasets and Dataloaders\n",
    "train_data = TripletData(root, train_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=16, shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_dataset = RevisitedDataset(root=root, phase='database', transform=val_transforms)\n",
    "offline_loader  = DataLoader(offline_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = checkpoint_names[0]\n",
    "model = timm.create_model(selected_model, pretrained=True).to(device)\n",
    "model.head = nn.Identity()\n",
    "model.train()\n",
    "# embed_dim = 1000\n",
    "# embed_dim = 768\n",
    "embed_dim = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "triplet_loss = TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95db7bdec88f4e9bb169e9d470dd2547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 188.0474090576172\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for data in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x1,x2,x3 = data\n",
    "        e1 = model(x1.to(device))\n",
    "        e2 = model(x2.to(device))\n",
    "        e3 = model(x3.to(device)) \n",
    "        \n",
    "        loss = triplet_loss(e1,e2,e3)\n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Train Loss: {}\".format(epoch_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline global feature DB generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = True\n",
    "model.eval()\n",
    "if compute:\n",
    "    index_flat = faiss.IndexFlatL2(embed_dim)   # build the index\n",
    "\n",
    "    img_indeces   = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prev = 1\n",
    "        for i, img in enumerate(offline_loader):\n",
    "            img = img.to(device)\n",
    "        \n",
    "            representation = model(img)\n",
    "            representation = representation.cpu().detach().numpy()\n",
    "            index_flat.add(representation) #add the representation to index\n",
    "            img_indeces.extend(list(range(i*prev, i*prev + len(img))))   #store the image name to find it later on\n",
    "            prev = len(img)\n",
    "            \n",
    "    index = index_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing INDEX to and reading from a disk, Looks like that it works with CPU index only?\n",
    "index_name = f'rparis_ft_{selected_model}.index'\n",
    "\n",
    "faiss.write_index(index_flat, os.path.join('indeces', index_name))\n",
    "\n",
    "# index = faiss.read_index(os.path.join(path, 'indeces', index_name))\n",
    "\n",
    "# with open(os.path.join(path, 'indeces', 'rparis_vit_tiny_indeces.txt'), 'w') as f:\n",
    "#     for i in img_indeces:\n",
    "#         f.write(f'{i}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_dataset  = RevisitedDataset(root=root, phase='query', setup='easy', transform=val_transforms)\n",
    "online_loader   = DataLoader(online_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: True\n",
      "Retrieved Image is OK?: True\n",
      "Retrieved Image is OK?: True\n",
      "Retrieved Image is OK?: True\n",
      "Retrieved Image is OK?: True\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: True\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n",
      "Retrieved Image is OK?: False\n"
     ]
    }
   ],
   "source": [
    "Is = []\n",
    "gnts = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img, gndt in online_loader:\n",
    "        img = img.to(device)\n",
    "\n",
    "        test_embed = model(img).cpu().detach().numpy()\n",
    "        test_embed = normalize(test_embed)\n",
    "        _, I = index.search(test_embed, 10000)\n",
    "\n",
    "        print(f\"Retrieved Image is OK?: {I[0][0] in gndt['ok']}\")\n",
    "\n",
    "        Is.append(I[0])\n",
    "        gnts.append(gndt)\n",
    "\n",
    "Is = np.array(Is)\n",
    "gnts = np.array(gnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035975331208757164"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP, *_ = evaluate.compute_map(Is.T, gnts)\n",
    "mAP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f536a1e4a2c81e102d58cbc69b7289784da24f3d148f0487ce42bd980675e709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
