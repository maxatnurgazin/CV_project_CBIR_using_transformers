{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import transforms, models, datasets\n",
    "import os\n",
    "import faiss\n",
    "from map import evaluate\n",
    "from revisited_dataset import RevisitedDataset\n",
    "from triplet_dataset import TripletData\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'roxford5k'\n",
    "\n",
    "path = 'E:/Datasets/paris/'\n",
    "root = f'E:/Datasets/paris/{dataset_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_names =  ['vit_small_patch16_224',\n",
    "                     'deit3_small_patch16_224',\n",
    "                     'swinv2_cr_small_224',\n",
    "                     'resnet50']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_dataset = RevisitedDataset(root=root, phase='database', dataset_name=dataset_name, transform=transform)\n",
    "offline_loader  = DataLoader(offline_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = checkpoint_names[0]\n",
    "model = timm.create_model(selected_model, pretrained=True).to(device)\n",
    "model.head = nn.Identity()\n",
    "model.eval()\n",
    "# embed_dim = 1000\n",
    "# embed_dim = 768\n",
    "embed_dim = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline global feature DB generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = True\n",
    "if compute:\n",
    "    index_flat = faiss.IndexFlatL2(embed_dim)   # build the index\n",
    "\n",
    "    img_indeces   = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prev = 1\n",
    "        for i, img in enumerate(offline_loader):\n",
    "            img = img.to(device)\n",
    "        \n",
    "            representation = model(img)\n",
    "            representation = representation.cpu().detach().numpy()\n",
    "            representation = normalize(representation)\n",
    "            index_flat.add(representation) #add the representation to index\n",
    "            img_indeces.extend(list(range(i*prev, i*prev + len(img))))   #store the image name to find it later on\n",
    "            prev = len(img)\n",
    "            \n",
    "    index = index_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing INDEX to and reading from a disk, Looks like that it works with CPU index only?\n",
    "index_name = f'{dataset_name}_{selected_model}.index'\n",
    "\n",
    "faiss.write_index(index_flat, os.path.join('indeces', index_name))\n",
    "\n",
    "# index = faiss.read_index(os.path.join(path, 'indeces', index_name))\n",
    "\n",
    "# with open(os.path.join(path, 'indeces', 'rparis_vit_tiny_indeces.txt'), 'w') as f:\n",
    "#     for i in img_indeces:\n",
    "#         f.write(f'{i}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_dataset  = RevisitedDataset(root=root, phase='query', setup='easy', dataset_name=dataset_name, transform=transform)\n",
    "online_loader   = DataLoader(online_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "Is = []\n",
    "gnts = []\n",
    "with torch.no_grad():\n",
    "    for img, gndt in online_loader:\n",
    "        img = img.to(device)\n",
    "\n",
    "        test_embed = model(img).cpu().detach().numpy()\n",
    "        test_embed = normalize(test_embed)\n",
    "        _, I = index.search(test_embed, 10000)\n",
    "\n",
    "        # print(f\"Retrieved Image is OK?: {I[0][0] in gndt['ok']}\")\n",
    "\n",
    "        Is.append(I[0])\n",
    "        gnts.append(gndt)\n",
    "\n",
    "Is = np.array(Is)\n",
    "gnts = np.array(gnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3488580073361315"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP, *_ = evaluate.compute_map(Is.T, gnts)\n",
    "mAP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f536a1e4a2c81e102d58cbc69b7289784da24f3d148f0487ce42bd980675e709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
